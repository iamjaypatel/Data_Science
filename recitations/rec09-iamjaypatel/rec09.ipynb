{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 1656 â€“ Introduction to Data Science \n",
    "\n",
    "## Instructor: Alexandros Labrinidis / Teaching Assistant: Xiaoting Li\n",
    "### Additional credits: Tahereh Arabghalizi, Phuong Pham, Zuha Agha, Anatoli Shein\n",
    "## Recitation 9: Collaborative Filtering & Similarity Metrics\n",
    "---\n",
    "In this recitation we will be doing a fun exercise to implement collaborative filtering for recommender systems. We will also learn how the choice of similarity metric in collaborative filtering can affect its output of predicted ratings. \n",
    "\n",
    "Packages you will need for the recitation are,\n",
    "\n",
    "* pandas\n",
    "* numpy\n",
    "* scipy\n",
    "\n",
    "Recall that numpy package provides nd-arrays and operations for easily manipulating them. \n",
    "Likewise, scipy provides an addtional suite of useful mathematical functions and distributions for numpy arrays, including distance functions which we will use in this recitation to compute the measure of similarity. We will only import the distance funcions we need for today's session as shown below. Note that cityblock is just another name for Manhattan distance metric seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cityblock, cosine\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based vs Item-Based Recommendation\n",
    "There are two type of collaborative filtering method: user-based and item-based.\n",
    "\n",
    "User-based recommendation assumes that similar users give similar ratings to each item. Whereas item-based recommendation assumes that similar items receive similar ratings from each user. You can think of them as a dual of each other. \n",
    "\n",
    "In this lab, we will walk through a toy example for user-based recommendation and you will try out item-based recommendation later in one of your tasks. \n",
    "\n",
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://data.cs1656.org/movies_example.csv')\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two ways to access dataframes rows are shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First way\n",
    "df[df['Name'] == 'The Matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second way\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exlude missing values or NaNs in a dataframe, we can use the notnull() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frank'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elaine'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform logical operations on the boolean object returned as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frank'].notnull() & df['Elaine'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select subset of rows and columns where the boolean value is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notmissing = df[['Frank','Elaine']][df['Frank'].notnull() & df['Elaine'].notnull()]\n",
    "df_notmissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics & Predicted Ratings\n",
    "Different distance metrics can be used to measure the similarity. In this recitation, we will use Euclidean, Manhattan, Pearson Correlation and Cosine distance metrics to measure the similarity.\n",
    "\n",
    "### Euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    dist = euclidean(df_subset['Frank'], df_subset[user])\n",
    "    sim_weights[user] = 1.0 / (1.0 + dist)\n",
    "print (\"similarity weights: %s\" % sim_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the predicted rating of 'Frank' for 'The Matrix'. We can get all ratings for a movie by accessing a row of the dataframe using iloc learnt earlier. We only slice the columns of ratings we need indicated by the index [1:-1]. In this case we do not need the first column 'Name' and the last column 'Frank'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df.iloc[0][1:-1]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find our predicted rating by multiplying each user weight with its corresponding rating for the movie matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan (Cityblock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our method of finding predicted rating using cityblock distance now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    dist = cityblock(df_subset['Frank'], df_subset[user])\n",
    "    sim_weights[user] = 1.0 / (1.0 + dist)\n",
    "print (\"similarity weights: %s\" % sim_weights)\n",
    "\n",
    "predicted_rating = 0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    sim_weights[user] = pearsonr(df_subset['Frank'], df_subset[user])[0]\n",
    "print (\"similarity weights: %s\" % sim_weights)\n",
    "\n",
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %s\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why nan?\n",
    "Because anything divided by 0 is undefined. Computing it again with this modfication gives the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    if (not np.isnan(sim_weights[user])):\n",
    "        predicted_rating += ratings[user] * sim_weights[user]\n",
    "        weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "For your tasks, use the class movie ratings data we collected in http://data.cs1656.org/movie_class_responses.csv. It will be fun to predict your misisng movie ratings by using ratings of your peers who share a similar taste in movies with you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 1: User-based Recommendation with Cosine Metric**\n",
    "\n",
    "Use movie ratings provided by the class to calculate ALL your missing movie ratingings using user-based recommendation with Cosine Metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 2: Item-based Recommendation with Cosine Metric**\n",
    "\n",
    "Repeat the task above by doing an item-based recommendation instead of a user based recommendation. To calculate a missing movie rating using item-based recommendation, you are supposed to find similarity between movies instead of users. In other words, you measure the similarity of your missing rating movie with movies that you have rated in the past. Then compute a weighted average using similar movie weights and their ratings to find out the predicted rating. You need to predict ALL your missing movie ratingings again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 3: User-based Recommendation with Cosine Metric**\n",
    "\n",
    "Repeat Task 1 while computing the weighted average using just top 10 most similar users instead of all users."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
